{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries \n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 as PretrainedModel, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil, random, os\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c4b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "bucket='s3-dle-24a2dfab-c6ea-475a-af08-290603fc8c40' # Or whatever you called your bucket\n",
    "data_key = 'twitter_fake_real_image_dataset.zip' # Where the file is within your bucket\n",
    "data_location = 's3://s3-dle-24a2dfab-c6ea-475a-af08-290603fc8c40/twitter_fake_real_image_dataset.zip'.format(bucket, data_key)\n",
    "!unzip -o twitter_fake_real_image_dataset.zip\n",
    "\n",
    "train_fake_dir = 'twitter_fake_real_image_dataset/train/fake'\n",
    "train_real_dir = 'twitter_fake_real_image_dataset/train/real'\n",
    "test_fake_dir = 'twitter_fake_real_image_dataset/test/fake'\n",
    "test_real_dir = 'twitter_fake_real_image_dataset/test/real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training fake images :', len(os.listdir(train_fake_dir ) ))\n",
    "print('total training real images :', len(os.listdir(train_real_dir ) ))\n",
    "\n",
    "print('total validation fake images :', len(os.listdir( test_fake_dir ) ))\n",
    "print('total validation real images :', len(os.listdir( test_real_dir ) ))\n",
    "\n",
    "folders = glob(train_dir + '/*')\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d695edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring the VGG16 model for Transfer Learning\n",
    "\n",
    "IMAGE_SIZE = [150, 150]\n",
    "\n",
    "ptm = PretrainedModel(\n",
    "    input_shape=[*IMAGE_SIZE, 3],\n",
    "    weights='imagenet',\n",
    "    include_top=False)\n",
    "\n",
    "# freeze pretrained model weights\n",
    "ptm.trainable = False\n",
    "\n",
    "# map the data into feature vectors\n",
    "# Keras image data generator returns classes one-hot encoded\n",
    "\n",
    "K = len(folders)\n",
    "x = Flatten()(ptm.output)\n",
    "x = Dense(K, activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=ptm.input, outputs=x)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# create an instance of ImageDataGenerator\n",
    "gen_train = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "gen_test = ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# create generators\n",
    "train_generator = gen_train.flow_from_directory(\n",
    "  train_dir,\n",
    "  shuffle=True,\n",
    "  target_size=(150, 150),\n",
    "  class_mode='sparse',\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "valid_generator = gen_test.flow_from_directory(\n",
    "  test_dir,\n",
    "  target_size=(150, 150),\n",
    "  batch_size=batch_size,\n",
    "  class_mode='sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9253fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for saving the best model files, which can be later used for validation dataset\n",
    "\n",
    "filepath=\"vgg16_model_fake_real_image.hdf5\"\n",
    "model_checkpoint=ModelCheckpoint(filepath,save_best_only=True,verbose=1)\n",
    "callbacks_list=[model_checkpoint]\n",
    "\n",
    "# fit the model\n",
    "vgg_withAug = model.fit(\n",
    "  train_generator,\n",
    "  validation_data=valid_generator,\n",
    "  epochs=300,\n",
    "  steps_per_epoch=13,\n",
    "  validation_steps=3,\n",
    "  verbose=2,\n",
    "  callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"s3://s3-dle-24a2dfab-c6ea-475a-af08-290603fc8c40/vgg16_model_fake_real_image.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62171209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy \n",
    "plt.plot(vgg_withAug .history['accuracy'], label='acc')\n",
    "plt.plot(vgg_withAug .history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plotting the loss plot for training and validation. \n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(vgg_withAug .history['loss'])\n",
    "plt.plot(vgg_withAug .history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Y_pred = model.predict_generator(valid_generator, 551 // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(valid_generator.classes, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
